{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from pathlib import Path\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_of_streams_actual1 = {\n",
    "    'Business Analysis': ['business analyst'], 'Business Intelligence': ['business intelligence', 'data analyst'],\n",
    "    'Cloud Computing': ['cloud', 'azure'], 'Compliance and Risk': ['compliance and risk', 'risk analyst'],\n",
    "    'Cyber Security': ['cyber security'], 'Development': ['software developer']}\n",
    "\n",
    "map_of_streams_actual2 = {\n",
    "    'Information Security Management': ['information security'], 'IT Service Management': ['technical support']\n",
    "    , 'Robotic Process Automation': ['rpa'],\n",
    "    'Testing': ['software tester', 'java test engineer']}\n",
    "\n",
    "map_of_streams_3 = {\n",
    "    'PMO': ['project manager']\n",
    "}\n",
    "map_of_streams_tester = {\n",
    "    'Testing': ['software test']\n",
    "}\n",
    "# map_of_streams_risk = {\n",
    "#     'Compliance and Risk': ['risk analyst']\n",
    "# }\n",
    "map_of_streams_info_security = {\n",
    "    'Information Security Management': ['information security']\n",
    "}\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "links = []\n",
    "streams = []\n",
    "descriptions = []\n",
    "\n",
    "def scrape_web_job_description(map_of_streams):\n",
    "    # specify driver path\n",
    "    DRIVER_PATH = '/Users/kaykay/Downloads/chromedriver'\n",
    "\n",
    "    # stop pop-ups\n",
    "    chrome_options = Options()\n",
    "\n",
    "    chrome_options.add_argument(\"--disable-infobars\")\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    # Pass the argument 1 to allow and 2 to block\n",
    "    chrome_options.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 1\n",
    "    })\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options, executable_path=DRIVER_PATH)\n",
    "    driver.get('https://www.indeed.co.uk/advanced_search')\n",
    "    #driver.find_element_by_id(\"popover-x\").click()\n",
    "    df_stream_description = pd.DataFrame()\n",
    "\n",
    "    for stream, job_descriptions in map_of_streams.items():\n",
    "        print(stream, ' >>>>>>>')\n",
    "\n",
    "        for job_description in job_descriptions:\n",
    "            print(job_description, '>>>>>')\n",
    "\n",
    "            # Search in the advanced page\n",
    "            # Input it also in the \"With all these words in the title\" box\n",
    "            try:\n",
    "                search_job = driver.find_element_by_xpath('//input[@id=\"as_and\"]')\n",
    "            except:\n",
    "                print(\"\")\n",
    "#                 close_popup = driver.find_element_by_id(\"popover-x\")\n",
    "#                 close_popup.click()\n",
    "#                 close_cookie_popup = driver.find_element_by_id(\"onetrust-accept-btn-handler\")\n",
    "#                 close_cookie_popup.click()\n",
    "            search_job = driver.find_element_by_xpath('//input[@id=\"as_and\"]')\n",
    "            search_job.send_keys([job_description])\n",
    "            driver.implicitly_wait(3)\n",
    "            \n",
    "            # Input it also in the \"With these words in the title\" box\n",
    "            search_job = driver.find_element_by_xpath('//input[@id=\"as_ttl\"]')\n",
    "            search_job.send_keys([job_description])\n",
    "\n",
    "            # for rpa look for robotic in the description as well\n",
    "            if stream == 'Robotic Process Automation':\n",
    "                search_job = driver.find_element_by_xpath('//input[@id=\"as_any\"]')\n",
    "                search_job.send_keys(['robotic'])\n",
    "            \n",
    "            driver.implicitly_wait(3)\n",
    "            # set display limit of 30 results per page\n",
    "            display_limit = driver.find_element_by_xpath('//select[@id=\"limit\"]//option[@value=\"50\"]')\n",
    "            display_limit.click()\n",
    "            # sort by date\n",
    "            sort_option = driver.find_element_by_xpath('//select[@id=\"sort\"]//option[@value=\"date\"]')\n",
    "            sort_option.click()\n",
    "            search_button = driver.find_element_by_xpath('//*[@id=\"fj\"]')\n",
    "            search_button.click()\n",
    "            try:\n",
    "                close_cookie_popup = driver.find_element_by_id(\"onetrust-accept-btn-handler\")\n",
    "                close_cookie_popup.click()\n",
    "            except:\n",
    "                print(\"No cookies popup\")\n",
    "\n",
    "            # Save the data to a table\n",
    "            # let the driver wait 3 seconds to locate the element before exiting out\n",
    "            driver.implicitly_wait(3)\n",
    "\n",
    "            for i in range(0, 40):\n",
    "\n",
    "                job_card = driver.find_elements_by_xpath('//div[contains(@class,\"clickcard\")]')\n",
    "\n",
    "                for job in job_card:\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        title = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').text\n",
    "                        job_titles.append(title)\n",
    "                        links.append(job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"href\"))\n",
    "                        streams.append(stream)\n",
    "\n",
    "                    except:\n",
    "                        title = job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"title\")\n",
    "                        job_titles.append(title)\n",
    "                        links.append(job.find_element_by_xpath('.//h2[@class=\"title\"]//a').get_attribute(name=\"href\"))\n",
    "                        streams.append(stream)\n",
    "\n",
    "                try:\n",
    "                    next_page = driver.find_element_by_xpath('//a[@aria-label={}]//span[@class=\"pn\"]'.format(i + 2))\n",
    "                    next_page.click()\n",
    "#                     WebDriverWait(driver, 3).until(EC.alert_is_present(),\n",
    "#                                                     'Timed out waiting for PA creation ' +\n",
    "#                                                     'confirmation popup to appear.')\n",
    "\n",
    "#                     alert = browser.switch_to.alert\n",
    "#                     alert.accept()\n",
    "                except ElementClickInterceptedException:\n",
    "                    close_popup = driver.find_element_by_id(\"popover-x\")\n",
    "                    close_popup.click()\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(\"no alert\")\n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    try:\n",
    "                        close_popup = driver.find_element_by_id(\"popover-x\")\n",
    "                        close_popup.click()\n",
    "\n",
    "                    except:\n",
    "                        try:\n",
    "                            next_page = driver.find_element_by_xpath('//a[@aria-label=\"Next\"]//span[@class=\"np\"]')\n",
    "                            next_page.click()\n",
    "                            driver.implicitly_wait(3)\n",
    "                        except:\n",
    "                            break\n",
    "\n",
    "                except:\n",
    "\n",
    "                    next_page = driver.find_element_by_xpath('//a[@aria-label=\"Next\"]//span[@class=\"np\"]')\n",
    "                    next_page.click()\n",
    "\n",
    "\n",
    "\n",
    "                print(\"Page: {}\".format(str(i + 2)))\n",
    "\n",
    "            # we need to be able to clear search and go on to the next role\n",
    "            # go to the clear advanced search page to insert new job description\n",
    "            driver.get('https://www.indeed.co.uk/advanced_search')\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            \n",
    "            driver.get(link)\n",
    "            jd = driver.find_element_by_xpath('//div[@id=\"jobDescriptionText\"]').text\n",
    "        except NoSuchElementException:\n",
    "            print(\" empty website\")\n",
    "            jd = \"\"\n",
    "                \n",
    "        \n",
    "        descriptions.append(jd)\n",
    "    \n",
    "    #del links[:]\n",
    "\n",
    "    df_stream_description['Title'] = job_titles\n",
    "    df_stream_description['Description'] = descriptions\n",
    "    df_stream_description['Stream'] = streams\n",
    "\n",
    "    return df_stream_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Analysis  >>>>>>>\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "alert accepted\n",
      "Page: 6\n",
      "alert accepted\n",
      "Page: 7\n",
      "alert accepted\n",
      "Page: 8\n",
      "alert accepted\n",
      "Page: 9\n",
      "alert accepted\n",
      "Page: 10\n",
      "alert accepted\n",
      "Page: 11\n",
      "alert accepted\n",
      "Page: 12\n",
      "alert accepted\n",
      "Page: 13\n",
      "alert accepted\n",
      "Page: 14\n",
      "alert accepted\n",
      "Page: 15\n",
      "alert accepted\n",
      "Page: 16\n",
      "alert accepted\n",
      "Page: 17\n",
      "alert accepted\n",
      "Page: 18\n",
      "Business Intelligence  >>>>>>>\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "alert accepted\n",
      "Page: 6\n",
      "alert accepted\n",
      "Page: 7\n",
      "alert accepted\n",
      "Page: 8\n",
      "alert accepted\n",
      "Page: 9\n",
      "alert accepted\n",
      "Page: 10\n",
      "alert accepted\n",
      "Page: 11\n",
      "Cloud Computing  >>>>>>>\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "alert accepted\n",
      "Page: 6\n",
      "alert accepted\n",
      "Page: 7\n",
      "alert accepted\n",
      "Page: 8\n",
      "alert accepted\n",
      "Page: 9\n",
      "alert accepted\n",
      "Page: 10\n",
      "alert accepted\n",
      "Page: 11\n",
      "alert accepted\n",
      "Page: 12\n",
      "alert accepted\n",
      "Page: 13\n",
      "alert accepted\n",
      "Page: 14\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "alert accepted\n",
      "Page: 6\n",
      "Compliance and Risk  >>>>>>>\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "Cyber Security  >>>>>>>\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "Development  >>>>>>>\n",
      "No cookies popup\n",
      "alert accepted\n",
      "Page: 2\n",
      "alert accepted\n",
      "Page: 3\n",
      "alert accepted\n",
      "Page: 4\n",
      "alert accepted\n",
      "Page: 5\n",
      "alert accepted\n",
      "Page: 6\n",
      "alert accepted\n",
      "Page: 7\n",
      "alert accepted\n",
      "Page: 8\n",
      "alert accepted\n",
      "Page: 9\n",
      "alert accepted\n",
      "Page: 10\n",
      "alert accepted\n",
      "Page: 11\n",
      "alert accepted\n",
      "Page: 12\n",
      "alert accepted\n",
      "Page: 13\n",
      "alert accepted\n",
      "Page: 14\n",
      "alert accepted\n",
      "Page: 15\n",
      "alert accepted\n",
      "Page: 16\n"
     ]
    }
   ],
   "source": [
    "df1 = scrape_web_job_description(map_of_streams_actual1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Title  \\\n",
      "1195                      Software Developer III (Ruby)   \n",
      "1196  Java Developer / Junior Software Engineer MSc PhD   \n",
      "1197                                 Software Developer   \n",
      "1198    Senior Software Engineer - Developer Experience   \n",
      "1199         Lead Developer / Senior Software Developer   \n",
      "\n",
      "                                            Description       Stream  \n",
      "1195  Weâ€™re Charlie, we build HR software and provid...  Development  \n",
      "1196  Java Developer / Junior Software Engineer (Mat...  Development  \n",
      "1197  An opportunity has popped up for a talented So...  Development  \n",
      "1198  Fastly helps people stay better connected with...  Development  \n",
      "1199  Our client is a fast-growing innovative compan...  Development  \n",
      "['Business Analysis' 'Business Intelligence' 'Cloud Computing'\n",
      " 'Compliance and Risk' 'Cyber Security' 'Development']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df1.tail())\n",
    "print(df1['Stream'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        1200 non-null   object\n",
      " 1   Description  1200 non-null   object\n",
      " 2   Stream       1200 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1[df1['Stream'] == 'Information Security Management'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/kaykay/Downloads/RecognitionEngineProject/recognitionengine/src/ml_determine_stream/df1_jd', 'wb') as fh:  # notice that you need the 'wb' for the dump\n",
    "    pickle.dump(df1, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Security Management  >>>>>>>\n",
      "information security >>>>>\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "IT Service Management  >>>>>>>\n",
      "technical support >>>>>\n",
      "No cookies popup\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Robotic Process Automation  >>>>>>>\n",
      "rpa >>>>>\n",
      "No cookies popup\n",
      "Testing  >>>>>>>\n",
      "software tester >>>>>\n",
      "No cookies popup\n",
      "Page: 2\n",
      "java test engineer >>>>>\n",
      "No cookies popup\n"
     ]
    }
   ],
   "source": [
    "df2 = scrape_web_job_description(map_of_streams_actual2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 231 entries, 0 to 230\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        231 non-null    object\n",
      " 1   Description  231 non-null    object\n",
      " 2   Stream       231 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Information Security Management' 'IT Service Management'\n",
      " 'Robotic Process Automation' 'Testing']\n"
     ]
    }
   ],
   "source": [
    "print(df2['Stream'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105 entries, 75 to 179\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        105 non-null    object\n",
      " 1   Description  105 non-null    object\n",
      " 2   Stream       105 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df2[df2['Stream'] == 'IT Service Management'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kaykay/Downloads/RecognitionEngineProject/recognitionengine/src/ml_determine_stream/df2_jd', 'wb') as fh:  # notice that you need the 'wb' for the dump\n",
    "    pickle.dump(df2, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90 entries, 570 to 659\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        90 non-null     object\n",
      " 1   Description  90 non-null     object\n",
      " 2   Stream       90 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1['Stream'] == 'Development'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMO  >>>>>>>\n",
      "project manager >>>>>\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n",
      "Page: 16\n",
      "Page: 17\n",
      "Page: 18\n",
      "Page: 19\n",
      "Page: 20\n"
     ]
    }
   ],
   "source": [
    "df3 = scrape_web_job_description(map_of_streams_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 285 entries, 0 to 284\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        285 non-null    object\n",
      " 1   Description  285 non-null    object\n",
      " 2   Stream       285 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kaykay/Downloads/RecognitionEngineProject/recognitionengine/src/ml_determine_stream/df_pmo', 'wb') as fh:  # notice that you need the 'wb' for the dump\n",
    "    pickle.dump(df3, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  >>>>>>>\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n"
     ]
    }
   ],
   "source": [
    "df_test = scrape_web_job_description(map_of_streams_tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        220 non-null    object\n",
      " 1   Description  220 non-null    object\n",
      " 2   Stream       220 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kaykay/Downloads/RecognitionEngineProject/recognitionengine/src/ml_determine_stream/df_test', 'wb') as fh:  # notice that you need the 'wb' for the dump\n",
    "    pickle.dump(df_test, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT Service Management  >>>>>>>\n",
      "technical support >>>>>\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n"
     ]
    }
   ],
   "source": [
    "# SCARPING ITSM\n",
    "# incorrect name of df\n",
    "df_test = scrape_web_job_description(map_of_streams_ITSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        105 non-null    object\n",
      " 1   Description  105 non-null    object\n",
      " 2   Stream       105 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compliance and Risk  >>>>>>>\n",
      "risk analyst >>>>>\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n"
     ]
    }
   ],
   "source": [
    "# Risk\n",
    "df_risk = scrape_web_job_description(map_of_streams_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        75 non-null     object\n",
      " 1   Description  75 non-null     object\n",
      " 2   Stream       75 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_risk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Security Management  >>>>>>>\n",
      "information security >>>>>\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n"
     ]
    }
   ],
   "source": [
    "# info_sec\n",
    "df_info_sec = scrape_web_job_description(map_of_streams_info_security)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        75 non-null     object\n",
      " 1   Description  75 non-null     object\n",
      " 2   Stream       75 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_info_sec.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may need more \n",
    "# compliance and risk\n",
    "# RPA\n",
    "# Cyber Security\n",
    "# Information Security\n",
    "# 11 streams >>> 4 needs to be checked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bite99ff6a3b0fa4ebc9040980d2ea3c6d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
